{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8d4f55-de8e-480e-aec3-fce2bee678bd",
   "metadata": {},
   "source": [
    "## REGRESSION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cab4dc-e2dc-4c3e-b49f-29103c9881ec",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ece76-7f9a-44c4-af2d-58808488bafd",
   "metadata": {},
   "source": [
    "# Q. Explain the difference between simple linear regression and multiple linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0592f36-234e-4a89-854d-522c7936fa8f",
   "metadata": {},
   "source": [
    "Simple liner regression and multiple liner regression both are the type of supervised meachine learning. When there is only one feature, by which we have to conclude the output, in such case we are using simple liner regression. In the liner regression we tried to find out a best fit line among the data points in a 2D plain, in such a way that line has max-less distance with the data points. The inntercept of that line called theta zero. To find out the intercept point of the best fit line we need to calculated the Global Minima wich we denoted as theta.\n",
    "\n",
    "- The formula to find the best fit line\n",
    "\n",
    " - H(x)= theta zero + theta one * x one\n",
    " \n",
    "    it is similar as \n",
    "- y= mx+c (The straight line farmula)\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "Multiple Regression\n",
    "\n",
    "\n",
    "- In multiple liner regression, there should be multiple input features by which we have to predict a conclustion as output. In such a case the best fit line is a 2d plain. Here we also denoted the intercept point as theta zero.\n",
    "\n",
    "   \n",
    "Framula\n",
    "\n",
    "- h(x)= theta zero(intercept point) + theta one(attempt for global minima)* x one(data point)+ theta two * x two............"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9bbde-8223-42c7-bb9e-102ca445d2ce",
   "metadata": {},
   "source": [
    "# Q. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465687d-7ad3-437c-b970-e36b8f38f917",
   "metadata": {},
   "source": [
    "When the data points are in big chaos, and there will be a not certain agrrigration of data points. The Polynomina; Regressio musty be preffered as it provide more accuracy to the model in such a case. Liner Regression is very usefull when the distribution of the data points is bit staright, but in suchn a case when the data has  seems to be distributed in bit curvical or round shape, the liner regression not worked. Because the best fit line cannot be covered the all data p;oints with a min distance and the R sequre (total Error Computed) is become high so that the accuracy of the model will be low.\n",
    "So the Plynominal Regression perfrom a well duty in that. It has two types\n",
    "\n",
    "- Simple Polynominal Regression\n",
    "- Multiple polynominal Reagression\n",
    "\n",
    "- Farmula\\\n",
    "\n",
    "*0o refered as theta zero\n",
    "\n",
    "  - h(x)= 0o*x1^zero\n",
    "\n",
    "in case of Polynominal Degree = 0 ,    h( x)= constant\n",
    "\n",
    "in case of Polynominal Degree= 1 ,     h(x)= Simple Liner Regression\n",
    "\n",
    "in case case of Polynominal Degree=2\n",
    "\n",
    "h(x)= 0o * x1^0 + 01 * X1^1 + 02 * x2^2.......... and so on as Polynomial Degree Increased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c6ce6d-21a3-49a3-b481-6a417e0cca34",
   "metadata": {},
   "source": [
    "# Q2. Discuss the assumptions of linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20435a3-f8ab-41b4-bc9e-f3543097667f",
   "metadata": {},
   "source": [
    "There are seven assumptions of liner Regression\n",
    "\n",
    "- Linear Model\n",
    "- No Multicolinearlity in the data\n",
    "- Number of observations Greater than the number of predictors\n",
    "- Each observation is unique\n",
    "- Predictors are distributed Normally\n",
    "- Homoscedasticity of Residuals or Equal Variances\n",
    "- No Autocorrelation in residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f705df-2e5f-41de-af90-c0251b5066f7",
   "metadata": {},
   "source": [
    "# Q. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e7cfb-77b6-4691-9e29-eb67229f6d4b",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm which is used to train machine learning models and neural networks. These model train theirself by the tarin data.\n",
    "The cost function and gradient descent help the model to increasing their accuracy by the each itreation of perametars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe009ab-e463-4df6-91f1-480a6a85f428",
   "metadata": {},
   "source": [
    "# Q. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815e71e-3c24-49be-8d79-6a02fe9a835d",
   "metadata": {},
   "source": [
    "In a data set, when two or more independent feature are highly co- related to each other, then we can remove the all feature excepting one of them, which has represented all other features. By doing this our inputs features are becoming less and which is good for our model..ie..processing. But it also decrase some accuracy of the model.\n",
    "\n",
    "- For identifying this there is a function of correlation. And basically it is a insder information abvout dataset , which is given with the data by team or employes of the projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f6a84-e7bd-4282-9169-d6dd37157d67",
   "metadata": {},
   "source": [
    "# Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797d7b9-1762-4840-abe7-36e02dd5f780",
   "metadata": {},
   "source": [
    "As we have already discussed, that liner regression is always be preffered when the given data has any specific liner scheme of sepreadness, and we use the polynominal regression when the data has not follow any scheme of sepration(Non- liner reltionship of data points) or in the curvuical type of spreadness among their axises. The Global Minima always want to be at excat bottom, it means the total of the error must be lesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc410b5-9e22-4300-8845-1c8b168adaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
